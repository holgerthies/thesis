%!TEX root = ../../thesis.tex
\section{Floating Point Arithmetic}
The traditional way to perform computations with real numbers on a computer is the use 
of \textbf{floating point arithmetic}. 

The floating point representation of a real number is a bit-string with a fixed
length.

Numbers are represented the following way:
\begin{definition}\label{def: floating point number}
	A floating point representation with base $b$ and precision $p$
	is a string $\pm d_0 . d_1 \dots d_{p-1} \times b^e$ with $0 \leq d_i < b$.	
	It represents the number
	$$ \pm b^e \cdot \sum_{i=0}^{p-1} d_i\beta^{-i} $$ 

	$\pm d_0 . d_1 \dots d_{p-1}$ is called the Mantissa and $e$ the exponent.
	
	The smallest and largest exponent allowed are $e_min$ and $e_max$.
	A floating point number can be encoded in
	$$ \lceil log_2(e_{max}-e_{min}+1) \rceil + \lceil  p \cdot log_2 (b) \rceil + 1 $$
	bits.
\end{definition}

Information on floating point arithmetic can for example be found in
\cite{Goldberg1991}.

If a real number does not fit into the above representation, it has to be
rounded appropriately.

Rounding also happens when an operation (e.g. multiplication) is applied and
the result does not fit into the finite representation anymore.

With the above definition the floating point representation of a number is not
unique. 
To guarantee uniqueness it is usually required that the representation  is
normalized, i.e. that $d_0 \neq 0$. 

Of course, $0$ can not be represented in this form, so often a special
representation is chosen for $0$.

Doing real number computations using floating point numbers will in most cases
lead to rounding errors.

One can distinguish two cases of errors, the \textbf{absolute error}, the
distance between the real result and the computed one, and the \textbf{relative
error}, the absolute error divided by the real result.

Floating point arithmetic is not necessarily associative, e.g. in many
programming languages for $x := 1e30$, $y := -1e30$ and $z := 1$ the expression
$(x+y)+z$ evaluates to $1$ while $x+(y+z)$ evaluates to $0$.
% Floating point arithmetic usually works by
% operating on
% only a fixed number of digits for computation.
% This makes computations fast, but can lead to large relative errors as in the following theorem: 
% \begin{theorem}
% 	The relative error when computing $x-y$ for floating point numbers $x,y$ can be as large as $b-1$. 
% \end{theorem}
% Note: Guard digits

Floating point types are often built into hardware, and thus computations can
be performed extremely quickly.
\subsection{The IEEE Standard}
	Floating point representations for binary base are standardized by IEEE 754 \cite{ieee}. 
	This standard is followed by almost all modern computers.

	The standard defines four different precisions: single, single-extended, double and double-extended.
  \begin{table}
	  	\centering
	    \begin{tabular}{ | c || c | c | c | c | c | }
	    \hline
	    Type & $p$ & $e_{max}$ & $e_{min}$ & exponent width (bits) & format width (bits) \\ \hline \hline
	    Single & 24 & +127 & -126 & 8 & 32 \\ \hline
	    Single-Extended & 32 & +1023 & $\leq -1022$ & $\leq 11$ & 43 \\ \hline
	    Double & 53 & +1023 & -1022 & 11 & 64 \\ \hline
	    Double-Extended & 64 & > 16383 & $\leq -16382$ & 15 & 79 \\ \hline
	    \end{tabular}
	    \caption{Parameters for the different types in the IEEE 754 standard}\label{table:IEEE floating point}
 \end{table}
 The details can be seen in Table \ref{table:IEEE floating point}.

 Apart from the numbers definable in the way of Definition \ref{def:
 floating point number}, the standard also introduces special quantities $-0, +0, \inf, +\inf$ and NAN (not a number). 
    
	It is required that the result of addition, subtraction, multiplication and division is exactly rounded, 
	i.e. the operation has to be performed exactly and then rounded afterwards.
	
  The rules for rounding are also defined in the standard.
  It is required to offer at least the following four rounding modes.
  \begin{enumerate}
    \item \textbf{Round to nearest} 
      All results are rounded to the nearest representable value. 
      If a result is in the middle of two representable values, the one where the
      lowest bit is zero is chosen.
    \item \textbf{Round toward $\infty$}
      All results are rounded to the smallest representable value larger than
      the result.
    \item \textbf{Round toward $-\infty$}
      All results are rounded to the largest representable value smaller than
      the result.
    \item \textbf{Round toward $0$}
      If the result is negative, it is rounded up, otherwise rounded down.
  \end{enumerate}
  The user should be able to select which of the rounding modes should be
  applied.
